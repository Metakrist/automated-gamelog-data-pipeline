{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d884b927-53c0-4fab-9f98-b2234cda52e7",
   "metadata": {},
   "source": [
    "# Cell 1 ‚Äî Imports and basic utilities\n",
    "\n",
    "This cell imports the primary libraries and utilities required by the automation. \n",
    "It establishes the foundational tools for database connectivity, data processing, time handling, file operations, and notebook output formatting.\n",
    "\n",
    "Purpose:\n",
    "- Provide database drivers and engine support (`pymysql`, `sqlalchemy`) for connecting to MySQL.\n",
    "- Load `pandas` for data manipulation and `datetime`/`time` for date/time logic and performance timing.\n",
    "- Include `os` for filesystem operations and `IPython.display` helpers for improved notebook feedback.\n",
    "\n",
    "Why this matters:\n",
    "- Centralizes dependency declarations so subsequent sections can rely on consistent APIs for querying, transforming, and exporting data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56f1378-f68f-45ea-a803-f8b77d14b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time as tm\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime, timedelta\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eced5f-289d-4ae0-a467-67d313dbc6ae",
   "metadata": {},
   "source": [
    "# Cell 2 ‚Äî Helper: formatted output (printmd)\n",
    "\n",
    "Defines a helper function that prints formatted Markdown messages for cleaner notebook output.\n",
    "\n",
    "Purpose:\n",
    "- Provide structured and readable runtime messages.\n",
    "- Differentiate normal logs from warnings or alerts using Markdown formatting.\n",
    "\n",
    "Why this matters:\n",
    "- Improves traceability and readability during manual or automated runs.\n",
    "\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6029440d-3aa6-44c2-b7f1-c656ae574047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print colored text in Jupyter Notebook\n",
    "def printmd(string, color=\"black\"):\n",
    "    display(Markdown(f\"<span style='color:{color}; font-size:16px;'>{string}</span>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83857316-169e-4cf1-9f5e-a245574ad73e",
   "metadata": {},
   "source": [
    "# Cell 3 ‚Äî Timer start / runtime logging\n",
    "\n",
    "Begins execution timing and logs the query start time.\n",
    "\n",
    "Purpose:\n",
    "- Capture when the automation started running.\n",
    "- Initialize performance tracking.\n",
    "\n",
    "Why this matters:\n",
    "- Useful for debugging and performance evaluation, especially during scheduled or batch runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b29dbed-386e-4a8a-9351-8dee9b4478eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:green; font-size:16px;'>Query Start Run at: Wed Oct  1 12:44:50 2025</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start timer\n",
    "query_start = tm.time()\n",
    "printmd(f\"Query Start Run at: {tm.asctime(tm.localtime(query_start))}\", \"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c41ca1-d5b5-4020-96ea-a2a0e8edc9fb",
   "metadata": {},
   "source": [
    "### üíª Dynamic Username Extraction ‚Äî PC Path Handling\n",
    "\n",
    "This code block dynamically determines the current computer‚Äôs username folder based on the working directory path.  \n",
    "It‚Äôs a crucial setup step for making the script **portable and adaptive** to any user environment, ensuring that file paths referencing local directories (like templates, reports, or exports) are automatically configured without manual editing.\n",
    "\n",
    "**Purpose:**\n",
    "To detect the logged-in user‚Äôs folder name on the local machine and store it in the variable `pc_username_folder`, allowing file path automation later in the script.\n",
    "\n",
    "**How It Works:**\n",
    "1. **Import the `os` Module** ‚Äì Provides functions to interact with the operating system, particularly for handling directories and paths.  \n",
    "2. **Get Current Working Directory** ‚Äì `os.path.abspath(os.getcwd())` retrieves the absolute path of the script‚Äôs current directory.  \n",
    "3. **Slice Path After `C:\\Users\\`** ‚Äì Calculates where the username starts in the path string using `len(\"c:\\\\users\\\\\")`.  \n",
    "4. **Locate the Next Folder Separator** ‚Äì Finds the next backslash `\\` to determine where the username ends.  \n",
    "5. **Extract the Username** ‚Äì Slices out the username portion and assigns it to `pc_username_folder`.  \n",
    "6. **Print the Username** ‚Äì Displays the detected username for verification and debugging purposes.\n",
    "\n",
    "**Example in Workflow:**\n",
    "The extracted username (`pc_username_folder`) is later used to build file paths dynamically,  \n",
    "for example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d57200-4a39-44bb-8181-d62d74f57c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tripl\\automation_project\\sorted_folder\\smash\\Smash\n",
      "username: tripl\n"
     ]
    }
   ],
   "source": [
    "#üîç Locating the directory/folder name after C:\\Users\\(x)\\\n",
    "#** (then adding the default directory of automation)\n",
    "\n",
    "# first = len(\"c:\\\\users\\\\\")\n",
    "# print(os.path.abspath(os.getcwd()))\n",
    "# pwd = os.path.abspath(os.getcwd())\n",
    "# second = pwd[first:len(pwd)]\n",
    "# third = second.find(\"\\\\\")\n",
    "# pc_username_folder =os.getenv('USERNAME')  # More reliable method than = second[0:third]\n",
    "# print(\"username: \"+ pc_username_folder)\n",
    "\n",
    "# import os\n",
    "first = len(\"c:\\\\users\\\\\")\n",
    "print(os.path.abspath(os.getcwd()))\n",
    "pwd = os.path.abspath(os.getcwd())\n",
    "second = pwd[first:len(pwd)]\n",
    "third = second.find(\"\\\\\")\n",
    "pc_username_folder = second[0:third]\n",
    "print(\"username: \"+ pc_username_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df1b76-0b4b-486e-b4a9-79493c60d339",
   "metadata": {},
   "source": [
    "### üß≠ Retrieving Stored Variables ‚Äî Using `%store -r`\n",
    "\n",
    "This code block retrieves key variables previously saved in the Jupyter environment using the `%store` magic command.  \n",
    "It ensures that values set in previous runs or notebooks (such as dates, file paths, and client identifiers) are automatically reloaded and ready for use, maintaining workflow continuity across multiple executions.\n",
    "\n",
    "**Purpose:**\n",
    "To restore essential parameters like date ranges, export filenames, and client details, which are required for the automation to function consistently across sessions.\n",
    "\n",
    "**How It Works:**\n",
    "1. **`%store -r` Command** ‚Äì The `-r` flag stands for ‚Äúrestore‚Äù. It retrieves a variable stored in Jupyter‚Äôs persistence system.  \n",
    "2. Each line restores a specific variable that was saved earlier using `%store variable_name`.  \n",
    "3. This allows the notebook to retain context even after being closed and reopened, without reinitializing values manually.\n",
    "\n",
    "**Variables Restored:**\n",
    "- **`start_date`** ‚Üí Beginning of the extraction period  \n",
    "- **`end_date`** ‚Üí End of the extraction period  \n",
    "- **`export_File`** ‚Üí File path for storing the extracted results  \n",
    "- **`filenamedt`** ‚Üí Dynamically generated filename string (usually contains start and end date info)  \n",
    "- **`client`** ‚Üí Client identifier for which the extraction is being performed  \n",
    "- **`row`** ‚Üí Excel row number reference or insertion point in the template\n",
    "\n",
    "**Example in Workflow:**\n",
    "This block is typically run before any data extraction or saving logic.  \n",
    "It ensures all downstream functions‚Äîlike querying the database or saving to Excel‚Äîhave access to the correct runtime variables set earlier in your automation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94570227-0bde-4111-8589-d4115d0c5ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias client\n",
      "no stored variable or alias row\n"
     ]
    }
   ],
   "source": [
    "%store -r start_date\n",
    "%store -r end_date\n",
    "%store -r export_File\n",
    "%store -r filenamedt\n",
    "%store -r client\n",
    "%store -r row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a10dd1c-3537-480a-a9c7-61db46d71447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #üíæ Save Location of excel file output\n",
    "# folder_path = fr'C:\\Python\\SMASH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fa6eed-996c-4f7a-bfc0-739072f8ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of the template in your computer¬∂\n",
    "#** make sure to place the template in this location\n",
    "# Define file paths\n",
    "# import_template = fr'C:\\Users\\{pc_username_folder}\\automation_project\\sorted_folder\\Templates\\V8 Templates\\SMASH_Template_DBGL.xlsx'\n",
    "# print(import_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcc3ec-c333-4de5-8f33-0e2edc5e1acd",
   "metadata": {},
   "source": [
    "### üîê Loading Login Credentials ‚Äî Game Back Office Access\n",
    "\n",
    "This cell runs an external notebook containing secure login credentials and retrieves the necessary credential data for authentication.  \n",
    "It modularizes sensitive information (like usernames, passwords, or tokens) by storing them in a separate notebook, keeping the main automation cleaner and more secure.\n",
    "\n",
    "**Purpose:**\n",
    "To execute a supporting notebook (`logincreds_gameBO_smash.ipynb`) that contains credential setup logic,  \n",
    "and restore the stored credential object (`smashcreds`) for use in login or data extraction processes.\n",
    "\n",
    "**How It Works:**\n",
    "1. **`%run` Magic Command** ‚Äì Executes another Jupyter Notebook file (`logincreds_gameBO_smash.ipynb`) as if its contents were part of this notebook.  \n",
    "   - This allows credentials or setup configurations to be defined externally and reused across multiple scripts.  \n",
    "2. **`%store -r smashcreds`** ‚Äì Restores the saved credential object (`smashcreds`) that was previously stored using `%store`.  \n",
    "   - This variable typically includes information like login URLs, usernames, and encrypted or masked passwords.\n",
    "\n",
    "**Example in Workflow:**\n",
    "This step is executed before initiating any web automation or API connections that require authentication.  \n",
    "By separating credentials into another notebook, the workflow maintains:\n",
    "- **Security** ‚Äî Sensitive data isn‚Äôt exposed directly in the main script.  \n",
    "- **Modularity** ‚Äî Credentials can be updated independently without altering the automation logic.  \n",
    "- **Reusability** ‚Äî The same credentials can be referenced by multiple automation scripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70bcf06-fcce-427b-aeb3-1ae876a236ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'smashcreds' (dict)\n"
     ]
    }
   ],
   "source": [
    "%run ./logincreds_gameBO_smash.ipynb\n",
    "%store -r smashcreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82727a4b-8427-44db-9f80-0c3cc5ab630f",
   "metadata": {},
   "source": [
    "### ‚è±Ô∏è Start Timer ‚Äî Query Execution Tracking\n",
    "\n",
    "This cell initializes a timer to monitor the duration of the data extraction process.  \n",
    "Tracking query runtime helps in performance optimization and provides visibility into how long each part of the automation takes to execute.\n",
    "\n",
    "**Purpose:**\n",
    "To record the exact timestamp when the query process begins, enabling the user to calculate total execution time later for reporting or troubleshooting.\n",
    "\n",
    "**How It Works:**\n",
    "1. **`query_start = tm.time()`** ‚Äì Captures the current time in seconds since the epoch (Unix timestamp) using the `time` module, and stores it in the variable `query_start`.  \n",
    "2. **`tm.asctime(tm.localtime(query_start))`** ‚Äì Converts the timestamp into a human-readable date and time format.  \n",
    "3. **`printmd()`** ‚Äì A custom or helper function designed to print styled text (in this case, green) within Jupyter Markdown cells for better readability.  \n",
    "4. Displays a message showing exactly when the query execution started.\n",
    "\n",
    "**Example in Workflow:**\n",
    "This timer serves as the **starting point** for runtime measurement.  \n",
    "At the end of the automation, another timestamp (`query_end`) will be captured, and the elapsed time (`query_end - query_start`) will show how long the query or extraction process took to complete.\n",
    "\n",
    "**Best Practice:**\n",
    "Including start and end timestamps in long-running scripts helps:\n",
    "- Identify slow queries or network delays  \n",
    "- Benchmark improvements after optimization  \n",
    "- Provide transparency when reviewing automation logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b281a9-d981-407a-9eb0-ee682039dbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:green; font-size:16px;'>Query Start Run at: Wed Oct  1 12:44:50 2025</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start timer\n",
    "query_start = tm.time()\n",
    "printmd(f\"Query Start Run at: {tm.asctime(tm.localtime(query_start))}\", \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9472a6-737d-4ea7-9f45-98471cf4e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f5fe4-3b89-4694-af28-3d907dff663f",
   "metadata": {},
   "source": [
    "### üéÆ Game Provider Configuration ‚Äî IDs and Data Range Setup\n",
    "\n",
    "This section defines the key parameters for identifying which game providers‚Äô data will be extracted and the specific timeframe for the query.  \n",
    "It acts as a **setup cell** that determines the scope of data retrieval within the automation process.\n",
    "\n",
    "**Purpose:**\n",
    "To specify:\n",
    "- The **list of game provider IDs** whose logs will be queried from the database.  \n",
    "- The **target database table** containing the gameplay data.  \n",
    "- The **optional time range** (`start_date`, `end_date`) that constrains the query results to a specific period.\n",
    "\n",
    "**How It Works:**\n",
    "1. **`gpid_list`** ‚Äì A Python list containing multiple game provider IDs as strings.  \n",
    "   - Each ID corresponds to a specific provider whose transaction or game logs will be retrieved.  \n",
    "   - The script later loops through this list to run queries or data validations for each provider automatically.  \n",
    "2. **`table`** ‚Äì Sets the name of the database table to be queried (e.g., `\"gaming_data\"`).  \n",
    "   - Keeping it in a variable allows easy modification if the table name changes or needs to be reused in SQL queries.  \n",
    "3. **`start_date` / `end_date` (commented)** ‚Äì These variables define the query‚Äôs time range.  \n",
    "   - Although commented out here, they are dynamically loaded earlier from `%store` commands or another date logic function.\n",
    "\n",
    "**Example in Workflow:**\n",
    "This block is executed before the main data extraction loop.  \n",
    "The script will use these variables to:\n",
    "- Dynamically build SQL queries,  \n",
    "- Filter data per provider ID, and  \n",
    "- Ensure only logs within the defined date range are processed.\n",
    "\n",
    "**Best Practice:**\n",
    "Keep provider IDs centralized in a list like this ‚Äî it improves scalability and avoids hardcoding IDs across multiple queries.  \n",
    "If new providers are added, they can be included here without modifying deeper parts of the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1100d3-4d7a-4274-a831-68d271527973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of game provider IDs\n",
    "gpid_list = ['6540','6516','6582','6479','6517','6575','6519','5936','6580','6578','6527','6581',           \n",
    "  '6577','6483','6528','6520','6482','6526','6515','6487','6621','6512','6579','6584','6518','6620',\n",
    "  '6525','6622','6524','6522','6576','6529','6583','6514','6513','6523']\n",
    "\n",
    "# Define table and time range\n",
    "table = \"gaming_data\"\n",
    "# start_date = \"2025-09-01 00:00:00\"\n",
    "# end_date = \"2025-09-30 23:59:59\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac146d54-f0f7-4205-9232-457f2a24603e",
   "metadata": {},
   "source": [
    "### üóìÔ∏è Date Conversion, Range Adjustment, and Dynamic Filename Generation\n",
    "\n",
    "This section converts stored date strings into datetime objects, adjusts the extraction time range,  \n",
    "and dynamically generates filenames that include start/end dates and time zone identifiers.  \n",
    "It ensures that both query parameters and output filenames remain consistent, traceable, and automatically aligned with the reporting period.\n",
    "\n",
    "**Purpose:**\n",
    "To handle all date-related processing and to create a unique, timestamped filename for saving the extracted game logs.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "1. **Convert Date Strings to Datetime Objects**\n",
    "   - `datetime.strptime()` converts the stored `start_date` and `end_date` strings (`YYYY-MM-DD HH:MM:SS`) into datetime objects for manipulation.\n",
    "\n",
    "2. **Adjust the End Date Range**\n",
    "   - Adds one day (`timedelta(days=1)`) and resets time to midnight (`.replace(hour=0, minute=0, second=0)`),  \n",
    "     ensuring that the full range through the final date is included in the extraction.\n",
    "\n",
    "3. **Reformat for Query Use**\n",
    "   - Converts `end_dt` back to a formatted string (`'%Y-%m-%d %H:%M:%S'`) for SQL query integration.\n",
    "   - `start_t` and `end_t` become ready-to-use query parameters.\n",
    "\n",
    "4. **Prepare Date Strings for Filename Usage**\n",
    "   - Reformats both dates (`st_dt` and `ed_dt`) to `YYYY-MM-DD` for cleaner file naming.\n",
    "   - Extracts **month and day portions** (`%b` and `%d`) to form compact start and end identifiers like `Jan31-Feb01`.\n",
    "\n",
    "5. **Append Time Zone Identifiers**\n",
    "   - Iterates through the list `tzgroup = [\"+8\", \"0\", \"-3\"]` and concatenates them into a suffix (e.g., `_+8_0_-3`),  \n",
    "     indicating multiple time zones covered by the report.\n",
    "\n",
    "6. **Construct the Dynamic Filename**\n",
    "   - Combines start name, end name, and timezone suffix ‚Üí e.g., `Jan31-Feb01_+8_0_-3`\n",
    "   - Stores this value in `filenamedt` using `%store` for reuse in other cells or notebooks.\n",
    "\n",
    "7. **Generate Export File Path**\n",
    "   - Defines `export_File` as the final Excel output path, e.g.:\n",
    "     ```\n",
    "     C:\\Python\\smash\\smash_Jan31-Feb01_+8_0_-3.xlsx\n",
    "     ```\n",
    "   - Stores the path with `%store` for consistent access in later parts of the workflow.\n",
    "\n",
    "8. **Print Outputs for Verification**\n",
    "   - Displays both the generated filename and full export path for confirmation.\n",
    "\n",
    "**Example in Workflow:**\n",
    "This cell prepares standardized filenames and ensures the correct extraction window is used when pulling game data from the database.  \n",
    "It helps in organizing output files by date and time zone, avoiding overwrites and simplifying archival management.\n",
    "\n",
    "**Best Practice:**\n",
    "- Always ensure `start_date` and `end_date` are in `YYYY-MM-DD HH:MM:SS` format to prevent parsing errors.  \n",
    "- Consider externalizing the timezone list (`tzgroup`) if reports often vary by region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ee1863-c3b1-425a-978f-4b04d1deea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'filenamedt' (str)\n",
      "Stored 'export_File' (str)\n",
      "Sep01-Sep30_+8_0_-3\n",
      "C:\\Python\\smash\\smash_Sep01-Sep30_+8_0_-3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Convert string dates to datetime objects\n",
    "start_dt = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "end_dt = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add one day to the end date\n",
    "end_dt += timedelta(days=1)\n",
    "end_dt = end_dt.replace(hour=0, minute=0, second=0)\n",
    "\n",
    "# Format the end date back to the desired string format\n",
    "start_t = start_dt\n",
    "end_t = end_dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#for filename use and saving to excel\n",
    "ed_dt_1 = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S')\n",
    "st_dt_1 = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "st_dt = datetime.strftime(st_dt_1, '%Y-%m-%d')  # ex.2024-01-31\n",
    "ed_dt = datetime.strftime(ed_dt_1, '%Y-%m-%d')\n",
    "\n",
    "# start date name\n",
    "month_s = st_dt_1.strftime('%b')  # month word format\n",
    "day_s = st_dt_1.strftime('%d')\n",
    "str_name = month_s + day_s\n",
    "\n",
    "# end date name\n",
    "month_e = ed_dt_1.strftime('%b')  # month word format\n",
    "day_e = ed_dt_1.strftime('%d')\n",
    "end_name = month_e + day_e\n",
    "\n",
    "# append time zone inclusion on name\n",
    "tzgroup = [\"+8\",\"0\",\"-3\"]\n",
    "tzname = \"\"\n",
    "for ele in tzgroup:\n",
    "    tzname += \"_\"\n",
    "    tzname += ele\n",
    "\n",
    "filenamedt = str_name + \"-\" + end_name + tzname\n",
    "%store filenamedt\n",
    "\n",
    "#export_File = fr'C:\\Python\\smash\\smashgldbextract_{filenamedt}.xlsx'\n",
    "export_File = fr'C:\\Python\\smash\\smash_{filenamedt}.xlsx'\n",
    "%store export_File\n",
    "save_File = export_File\n",
    "\n",
    "print(filenamedt)\n",
    "print(export_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8f7cb-a862-497b-b784-20066ccc153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully via SOCKS proxy!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Database Connection via SOCKS Proxy (No Outline)\n",
    "# ===============================================\n",
    "\n",
    "import pymysql\n",
    "import socks\n",
    "import socket\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# -----------------------------------------------\n",
    "# SOCKS Proxy Configuration\n",
    "# (Matches DBeaver setup: 127.0.0.1:1080)\n",
    "# -----------------------------------------------\n",
    "socks.set_default_proxy(socks.SOCKS5, \"127.0.0.1\", 1080)\n",
    "socket.socket = socks.socksocket\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Database Credentials\n",
    "# -----------------------------------------------\n",
    "db_user = \"username#\"\n",
    "db_password = \"password#\"\n",
    "db_host = \"30.123.3.123\"\n",
    "db_port = 1234\n",
    "db_name = \"dbname\"\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Create SQLAlchemy Engine\n",
    "# -----------------------------------------------\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Test Connection\n",
    "# -----------------------------------------------\n",
    "with engine.connect() as connection:\n",
    "    print(\"‚úÖ Connected successfully via SOCKS proxy!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4f17c2f-73a1-4678-966a-6d6340ba1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Result will be printed.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# Function: query_incr_multiple\n",
    "# Description:\n",
    "#     Fetches game logs for multiple Game Platform IDs (GPIDs)\n",
    "#     within a specified date range. Automatically adjusts\n",
    "#     the start and end times to cover the full day (00:00:00‚Äì23:59:59).\n",
    "# ==============================================================\n",
    "\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import time as tm\n",
    "\n",
    "def query_incr_multiple(gpid_list, table, start_date, end_date, engine):\n",
    "    \"\"\"\n",
    "    Fetch game logs for multiple game platform IDs within a modified time range.\n",
    "    \n",
    "    Args:\n",
    "        gpid_list (list): List of game platform IDs.\n",
    "        table (str): Database table name.\n",
    "        start_date (str): Original start date in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "        end_date (str): Original end date in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "        engine: Database engine connection.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Aggregated query results.\n",
    "    \"\"\"\n",
    "    # -------------------------------------------\n",
    "    # Convert to datetime and adjust time range\n",
    "    # -------------------------------------------\n",
    "    \n",
    "    # Convert to datetime\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Modify time portion\n",
    "    mod_start_dt = start_dt.replace(hour=0, minute=0, second=0)\n",
    "    mod_end_dt = end_dt.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    # Convert back to string \n",
    "    mod_start_str = mod_start_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    mod_end_str = mod_end_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Convert list of GPIDs to a SQL-compatible string\n",
    "    gpid_list_str = \",\".join(map(str, gpid_list))\n",
    "\n",
    "    # SQL Query: Fetch all GPIDs at once (faster!)\n",
    "    \n",
    "    # gl_query = f\"\"\"\n",
    "    # SELECT \n",
    "    #     gl.game_platform_id, \n",
    "    #     gl.end_at, \n",
    "    #     SUM(gl.real_betting_amount) AS Bet, \n",
    "    #     SUM(gl.result_amount) AS Payout  \n",
    "    # FROM game_logs gl\n",
    "    # JOIN player p ON p.playerId = gl.player_id\n",
    "    # WHERE gl.end_at BETWEEN '{mod_start_str}' AND '{mod_end_str}' \n",
    "    #     AND gl.flag = '1'\n",
    "    #     AND gl.game_platform_id IN ({gpid_list_str})  -- Fetch all GPIDs in one query\n",
    "    # GROUP BY gl.game_platform_id;\n",
    "    # \"\"\"\n",
    "    gl_query = f\"\"\"\n",
    "    SELECT \n",
    "        gl.game_platform_id, \n",
    "        gl.end_at, \n",
    "        SUM(gl.real_betting_amount) AS Bet, \n",
    "        SUM(gl.result_amount * -1) AS Payout  \n",
    "    FROM game_logs gl\n",
    "    JOIN player p ON p.playerId = gl.player_id\n",
    "    WHERE gl.end_at BETWEEN '{mod_start_str}' AND '{mod_end_str}' \n",
    "        AND gl.flag = '1'\n",
    "        AND gl.game_platform_id IN ({gpid_list_str})  -- Fetch all GPIDs in one query\n",
    "    GROUP BY gl.game_platform_id;\n",
    "    \"\"\"\n",
    "    # -------------------------------------------\n",
    "    # Execute query and handle results\n",
    "    # -------------------------------------------\n",
    "    \n",
    "    print(\"Executing optimized query...\\n\")\n",
    "    try:\n",
    "        # Execute query\n",
    "        result = pd.read_sql_query(gl_query, engine)\n",
    "        if result.empty:\n",
    "            print(\"No data found. Returning empty DataFrame.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "print(\"Done! Result will be printed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f1370f-9e2a-4f93-aa16-a0644248fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing optimized query...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run query for multiple GPIDs\n",
    "df = query_incr_multiple(gpid_list, table, start_date, end_date, engine)\n",
    "\n",
    "# Display result\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f9833ba-ac03-4798-a9f8-963dbd047e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_start = tm.time()\n",
    "# query_time = tm.asctime(tm.localtime(query_start))\n",
    "\n",
    "# # Function to display colored text\n",
    "# def printmd(string, color=\"black\"):\n",
    "#     display(Markdown(f\"<span style='color:{color}; font-size:16px;'>{string}</span>\"))\n",
    "\n",
    "# # Print in green\n",
    "# printmd(f\"Query Start Run at: {query_time}\", \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f75cb244-dba0-4406-a51f-08d49b61d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red; font-size:16px;'>Query End Run at: Wed Oct  1 12:45:27 2025</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue; font-size:16px;'>Total Execution Time: 37.14 seconds</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# End Timer and Display Total Execution Time\n",
    "# ============================================\n",
    "\n",
    "# Stop timer\n",
    "query_end = tm.time()\n",
    "printmd(f\"Query End Run at: {tm.asctime(tm.localtime(query_end))}\", \"red\")\n",
    "\n",
    "# Calculate and print total execution time\n",
    "execution_time = query_end - query_start\n",
    "printmd(f\"Total Execution Time: {execution_time:.2f} seconds\", \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b9d355-81a3-401b-9b1d-41bf3c62346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"game_logs_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a438130-7edd-40a7-8ccf-df55bc933061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Display Formatting for Floating-Point Numbers\n",
    "# ============================================\n",
    "\n",
    "# Ensures that all floating-point numbers in DataFrames\n",
    "# are displayed with exactly 5 decimal places for consistency.\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format #specifies that floating-point numbers will be displayed with 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f8cdb2-9a1c-41fa-9a61-9aa9315629f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    game_platform_id              end_at           Bet       Payout\n",
      "0               5936 2025-09-01 09:26:32   17988.34000   2152.87000\n",
      "1               6479 2025-09-01 14:00:16   16938.20000  -1797.31000\n",
      "2               6483 2025-09-01 11:14:14   12979.50000   5375.90000\n",
      "3               6487 2025-09-03 18:06:17   26941.08200   -110.31200\n",
      "4               6512 2025-09-06 20:34:51      66.40000    -23.40000\n",
      "5               6514 2025-09-01 20:41:01    4979.00000    265.50000\n",
      "6               6515 2025-09-02 22:13:38       7.25000      5.80000\n",
      "7               6516 2025-09-05 18:43:07      81.10000     10.55600\n",
      "8               6518 2025-09-01 17:42:15    6303.15000   1904.67000\n",
      "9               6519 2025-09-01 09:34:03    6605.40000   1294.56000\n",
      "10              6520 2025-09-04 20:53:18    5454.75000    772.74000\n",
      "11              6522 2025-09-05 21:18:43    2462.10000     15.13000\n",
      "12              6523 2025-09-03 04:41:28    1535.50000     46.12000\n",
      "13              6526 2025-09-01 08:04:10  125451.60000  25019.96000\n",
      "14              6527 2025-09-02 19:17:58     518.84000    -30.56000\n",
      "15              6528 2025-09-01 00:29:02    3236.50000    543.31000\n",
      "16              6529 2025-09-01 00:00:01 5577635.43000 147706.67000\n",
      "17              6540 2025-09-02 02:25:50    6012.25000   1971.25000\n",
      "18              6575 2025-09-01 22:04:30     951.80000    188.57000\n",
      "19              6576 2025-09-01 19:05:23    8886.40000    799.44000\n",
      "20              6577 2025-09-04 21:12:07     380.03000    105.96000\n",
      "21              6578 2025-09-02 22:24:41    6780.80000     51.78000\n",
      "22              6579 2025-09-12 19:35:39      71.00000     13.22000\n",
      "23              6580 2025-09-01 00:02:14     892.80000    326.11000\n",
      "24              6581 2025-09-01 00:00:03       1.00000      0.48000\n",
      "25              6582 2025-09-04 14:06:50      21.00000      1.35000\n",
      "26              6583 2025-09-05 17:58:26    6176.50000    881.50000\n",
      "27              6584 2025-09-17 04:19:11      30.00000     25.00000\n",
      "28              6621 2025-09-01 18:19:25    3234.02000    493.52000\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c80aa59-c079-4d17-987d-9d6629479353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing row mapping of each GPID\n",
      "{'6540': '2', '6516': '3', '6582': '4', '6479': '5', '6517': '6', '6575': '7', '6519': '8', '5936': '9', '6580': '10', '6578': '11', '6527': '12', '6581': '13', '6577': '14', '6483': '15', '6528': '16', '6520': '17', '6482': '18', '6526': '19', '6515': '20', '6487': '21', '6621': '22', '6512': '23', '6579': '24', '6584': '25', '6518': '26', '6620': '27', '6525': '29', '6622': None, '6524': '31', '6522': '32', '6576': '33', '6529': '34', '6583': '38', '6514': '39', '6513': '40', '6523': '41'}\n"
     ]
    }
   ],
   "source": [
    "def get_row_for_gpid(gpid, smashcreds):\n",
    "    \"\"\"\n",
    "    Fetch the row number for a given GPID from the smashcreds dictionary.\n",
    "    \n",
    "    Args:\n",
    "        gpid (str): The game platform ID to look up.\n",
    "        smashcreds (dict): Dictionary containing GPID-to-row mappings.\n",
    "    \n",
    "    Returns:\n",
    "        str: The row number associated with the given GPID, or None if not found.\n",
    "    \"\"\"\n",
    "    for provider, data in smashcreds.items():\n",
    "        gpid_row_key = f\"{gpid}row\"  # Ensure the key matches exactly with the GPID's row\n",
    "        if gpid_row_key in data:\n",
    "            return data[gpid_row_key]\n",
    "    return None  # Return None if the GPID is not found\n",
    "\n",
    "# Example usage\n",
    "#gpid_list = ['5940', '5941', '5942', '5943', '6198']\n",
    "row_mapping = {gpid: get_row_for_gpid(gpid, smashcreds) for gpid in gpid_list}\n",
    "\n",
    "# Print the row mapping for each GPID\n",
    "print('Printing row mapping of each GPID')\n",
    "print(row_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b6e944d-10ef-4b05-995d-6b1c7ba5d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing existing file: C:\\Python\\smash\\smash_Sep01-Sep30_+8_0_-3.xlsx\n",
      "Results have been successfully saved to: C:\\Python\\smash\\smash_Sep01-Sep30_+8_0_-3.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "# Define the path for the template and the new file\n",
    "import_template = fr'C:\\Users\\{pc_username_folder}\\automation_project\\sorted_folder\\Templates\\V8 Templates\\SMASH_Template_SBE.xlsx'\n",
    "export_File = fr'C:\\Python\\smash\\smash_{filenamedt}.xlsx'\n",
    "\n",
    "# Open the existing Excel file for reuse (if it already exists)\n",
    "def reuse_existing_excel(export_File, df, row_mapping):\n",
    "    \"\"\"\n",
    "    Reuse the existing Excel file and insert the query results into the correct rows.\n",
    "    \n",
    "    Args:\n",
    "        export_File (str): Path to the exported Excel file.\n",
    "        df (DataFrame): The query result DataFrame.\n",
    "        row_mapping (dict): A dictionary mapping GPIDs to the row numbers.\n",
    "    \"\"\"\n",
    "    # Open the workbook and select the active sheet\n",
    "    book = load_workbook(export_File)\n",
    "    sheet = book.active  # You can specify a sheet name if needed, e.g., sheet = book[\"Sheet1\"]\n",
    "\n",
    "    # Track the last used row for appending new data (optional)\n",
    "    last_row = sheet.max_row\n",
    "\n",
    "    # Insert the results from the DataFrame into the correct columns\n",
    "    for _, row in df.iterrows():\n",
    "        gpid = row['game_platform_id']\n",
    "        bet = row['Bet']\n",
    "        payout = row['Payout']\n",
    "\n",
    "        # Get the corresponding row number from the mapping\n",
    "        row_num = row_mapping.get(str(gpid))\n",
    "\n",
    "        if row_num:\n",
    "            # Insert data into columns F (SBE BET) and J (SBE PO)\n",
    "            sheet[f'F{row_num}'] = bet  # Column F for SBE BET\n",
    "            sheet[f'J{row_num}'] = payout  # Column J for SBE PO\n",
    "\n",
    "    # Save the updated workbook without overwriting the template\n",
    "    book.save(export_File)\n",
    "    book.close()\n",
    "\n",
    "# Function to load the template and copy it for the first time if necessary\n",
    "def create_or_reuse_template():\n",
    "    # Only copy the template if it doesn't exist yet (for first-time use)\n",
    "    if not os.path.exists(export_File):\n",
    "        copyfile(import_template, export_File)\n",
    "        print(f\"Template copied to {export_File}\")\n",
    "    else:\n",
    "        print(f\"Reusing existing file: {export_File}\")\n",
    "\n",
    "# Reuse the existing file or create a new one if it doesn't exist\n",
    "create_or_reuse_template()\n",
    "\n",
    "# Insert the results into the reusable file\n",
    "reuse_existing_excel(export_File, df, row_mapping)\n",
    "\n",
    "print(f\"Results have been successfully saved to: {export_File}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfdc0a-f74a-44dc-bf2f-59e316fc0c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "024cbdd7-94e5-4f38-8497-d7ab993bac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpid_list =  ['crash','dice','double'] #we use the game to the loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d0aa288-ea52-40d4-8389-dc4aac64f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing row mapping of each game\n",
      "{'crash': '35', 'dice': '36', 'double': '37'}\n"
     ]
    }
   ],
   "source": [
    "def get_row_for_gpid(gpid, smashcreds):\n",
    "    \"\"\"\n",
    "    Fetch the row number for a given GPID from the smashcreds dictionary.\n",
    "    \n",
    "    Args:\n",
    "        gpid (str): The game platform ID to look up.\n",
    "        smashcreds (dict): Dictionary containing GPID-to-row mappings.\n",
    "    \n",
    "    Returns:\n",
    "        str: The row number associated with the given GPID, or None if not found.\n",
    "    \"\"\"\n",
    "    for provider, data in smashcreds.items():\n",
    "        gpid_row_key = f\"{gpid}row\"  # Ensure the key matches exactly with the GPID's row\n",
    "        if gpid_row_key in data:\n",
    "            return data[gpid_row_key]\n",
    "    return None  # Return None if the GPID is not found\n",
    "\n",
    "# Example usage\n",
    "#gpid_list = ['5940', '5941', '5942', '5943', '6198']\n",
    "row_mapping = {gpid: get_row_for_gpid(gpid, smashcreds) for gpid in gpid_list}\n",
    "\n",
    "# Print the row mapping for each GPID\n",
    "print('Printing row mapping of each game')\n",
    "print(row_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87ea834c-2c7d-4cdd-babb-9fbf57bf80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# import time as tm\n",
    "\n",
    "def query_incr_multiple(gpid_list, table, start_date, end_date, engine):\n",
    "    \"\"\"\n",
    "    Fetch game logs for multiple game platform IDs within a modified time range.\n",
    "    \n",
    "    Args:\n",
    "        gpid_list (list): List of game platform IDs.\n",
    "        table (str): Database table name.\n",
    "        start_date (str): Original start date in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "        end_date (str): Original end date in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "        engine: Database engine connection.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Aggregated query results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to datetime\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # # Modify time portion\n",
    "    mod_start_dt = start_dt.replace(hour=0, minute=0, second=0)\n",
    "    mod_end_dt = end_dt.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    # # Convert back to string\n",
    "    mod_start_str = mod_start_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    mod_end_str = mod_end_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Convert list of GPIDs to a SQL-compatible string\n",
    "    #gpid_list_str = \",\".join(map(str, gpid_list)) #used in gameplatform_id\n",
    "    gpid_list_str = \",\".join(f\"'{game}'\" for game in gpid_list) #used for gpid_list =  ['crash','dice','double'] #we use the game to the loop function\n",
    "\n",
    "    # SQL Query: Fetch all GPIDs at once (faster!)\n",
    "    gl_query = f\"\"\"\n",
    "    SELECT \n",
    "        gl.game, \n",
    "        gl.end_at, \n",
    "        SUM(gl.real_betting_amount) AS Bet, \n",
    "        SUM(gl.result_amount * -1) AS Payout \n",
    "        # gl.game_platform_id\n",
    "    FROM game_logs gl\n",
    "    JOIN player p ON p.playerId = gl.player_id\n",
    "    WHERE gl.end_at BETWEEN '{mod_start_str}' AND '{mod_end_str}' \n",
    "        AND gl.flag = '1'\n",
    "        AND gl.game_platform_id = '5928'  -- Fetch all GPIDs in one query -in this case fetch all is not applicable we hardcoded the gpid and use gamtypeID\n",
    "        AND gl.game IN ({gpid_list_str})\n",
    "    GROUP BY gl.game;\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Executing optimized query...\\n\")\n",
    "    try:\n",
    "        # Execute query\n",
    "        result = pd.read_sql_query(gl_query, engine)\n",
    "        if result.empty:\n",
    "            print(\"No data found. Returning empty DataFrame.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4aaf1195-f36c-48d2-af5a-3cf2c17ab007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing optimized query...\n",
      "\n",
      "     game              end_at            Bet       Payout\n",
      "0   crash 2025-09-01 00:00:18 17549921.55640 589905.86029\n",
      "1    dice 2025-09-01 00:00:07  3285067.69400  89176.54253\n",
      "2  double 2025-09-01 00:00:12  4040220.80550 302283.88110\n"
     ]
    }
   ],
   "source": [
    "# Run query for multiple GPIDs\n",
    "df = query_incr_multiple(gpid_list, table, start_date, end_date, engine)\n",
    "\n",
    "# Display result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fe97823-6ba6-43a0-9a5f-5ad22268e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()  # Properly closes the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8286a459-00ad-4797-a85c-d5184af1b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red; font-size:16px;'>Query End Run at: Wed Oct  1 12:45:46 2025</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue; font-size:16px;'>Total Execution Time: 56.01 seconds</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#End timer\n",
    "query_end = tm.time()\n",
    "printmd(f\"Query End Run at: {tm.asctime(tm.localtime(query_end))}\", \"red\")\n",
    "\n",
    "# Calculate and print total execution time\n",
    "execution_time = query_end - query_start\n",
    "printmd(f\"Total Execution Time: {execution_time:.2f} seconds\", \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "774289a7-bb17-46e0-a397-1d2f5fdd82af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing existing file: C:\\Python\\smash\\smash_Sep01-Sep30_+8_0_-3.xlsx\n",
      "Results have been successfully saved to: C:\\Python\\smash\\smash_Sep01-Sep30_+8_0_-3.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "# Define the path for the template and the new file\n",
    "import_template = fr'C:\\Users\\{pc_username_folder}\\automation_project\\sorted_folder\\Templates\\V8 Templates\\SMASH_Template_SBE.xlsx'\n",
    "export_File = fr'C:\\Python\\smash\\smash_{filenamedt}.xlsx'\n",
    "\n",
    "# Open the existing Excel file for reuse (if it already exists)\n",
    "def reuse_existing_excel(export_File, df, row_mapping):\n",
    "    \"\"\"\n",
    "    Reuse the existing Excel file and insert the query results into the correct rows.\n",
    "    \n",
    "    Args:\n",
    "        export_File (str): Path to the exported Excel file.\n",
    "        df (DataFrame): The query result DataFrame.\n",
    "        row_mapping (dict): A dictionary mapping GPIDs to the row numbers.\n",
    "    \"\"\"\n",
    "    # Open the workbook and select the active sheet\n",
    "    book = load_workbook(export_File)\n",
    "    sheet = book.active  # You can specify a sheet name if needed, e.g., sheet = book[\"Sheet1\"]\n",
    "\n",
    "    # Track the last used row for appending new data (optional)\n",
    "    last_row = sheet.max_row\n",
    "\n",
    "    # Insert the results from the DataFrame into the correct columns\n",
    "    for _, row in df.iterrows():\n",
    "        gpid = row['game']\n",
    "        bet = row['Bet']\n",
    "        payout = row['Payout']\n",
    "\n",
    "        # Get the corresponding row number from the mapping\n",
    "        row_num = row_mapping.get(str(gpid))\n",
    "\n",
    "        if row_num:\n",
    "            # Insert data into columns F (SBE BET) and J (SBE PO)\n",
    "            sheet[f'F{row_num}'] = bet  # Column F for SBE BET\n",
    "            sheet[f'J{row_num}'] = payout  # Column J for SBE PO\n",
    "\n",
    "    # Save the updated workbook without overwriting the template\n",
    "    book.save(export_File)\n",
    "    book.close()\n",
    "\n",
    "# Function to load the template and copy it for the first time if necessary\n",
    "def create_or_reuse_template():\n",
    "    # Only copy the template if it doesn't exist yet (for first-time use)\n",
    "    if not os.path.exists(export_File):\n",
    "        copyfile(import_template, export_File)\n",
    "        print(f\"Template copied to {export_File}\")\n",
    "    else:\n",
    "        print(f\"Reusing existing file: {export_File}\")\n",
    "\n",
    "# Reuse the existing file or create a new one if it doesn't exist\n",
    "create_or_reuse_template()\n",
    "\n",
    "# Insert the results into the reusable file\n",
    "reuse_existing_excel(export_File, df, row_mapping)\n",
    "\n",
    "print(f\"Results have been successfully saved to: {export_File}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
